# ğŸ¤Ÿ LibraVoice  

**Sistema de traduÃ§Ã£o de Libras para voz desenvolvido em Python**  

[![LicenÃ§a](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![Version](https://img.shields.io/badge/Version-2.1.2-green.svg)]()
[![Status](https://img.shields.io/badge/status-em%20desenvolvimento-yellow.svg)]()
[![Deploy](https://img.shields.io/badge/deploy-inactive-red.svg)]()

## ğŸ“Œ SumÃ¡rio

1. [Sobre o Projeto](#-sobre-o-projeto)  
2. [Objetivos](#-objetivos)  
3. [Tecnologias](#-tecnologias)  
4. [Funcionalidades](#-funcionalidades)  
5. [PrÃ©-requisitos](#%EF%B8%8F-prÃ©-requisitos)  
6. [InstalaÃ§Ã£o](#%EF%B8%8F-instalaÃ§Ã£o)  
7. [Como utilizar](#-como-utilizar)
8. [Estrutura do Projeto](#-estrutura-do-projeto)
9. [ContribuiÃ§Ã£o](#-contribuiÃ§Ã£o)  
10. [LicenÃ§a](#-licenÃ§a)  
11. [Contato](#-contato)  
12. [Recursos Adicionais](#-recursos-adicionais)  

## ğŸ’» Sobre o Projeto  

O **LibraVoice** Ã© um projeto de extensÃ£o acadÃªmica que utiliza visÃ£o computacional e processamento de linguagem natural para criar uma ponte comunicacional entre pessoas surdas e ouvintes

- **MotivaÃ§Ã£o**: CarÃªncia social de sistemas faciliadores de comunicaÃ§Ã£o
- **PÃºblico-alvo**: Bancada Avaliativa, Estudantes de ProgramaÃ§Ã£o, Comunidade de Desenvolvimento e PCDs 
- **Problema resolvido**: Barreira de comunicaÃ§Ã£o entre surdos e ouvintes
- **Diferencial**: ConversÃ£o simultÃ¢nea para texto e voz  
- **Metodologia**: Desenvolvimento Ã¡gil com Scrum  

## ğŸ¯ Objetivos  

### ğŸ› ï¸ TÃ©cnicos  
- Desenvolver sistema de reconhecimento de gestos em tempo real  
- Implementar pipeline completo: gesto â†’ texto â†’ voz  
- AlcanÃ§ar precisÃ£o mÃ­nima de 85% na detecÃ§Ã£o  

### ğŸ“š AcadÃªmicos  
- Aplicar conceitos de visÃ£o computacional e IA
- Implementar metodologias Ã¡geis na prÃ¡tica  
- Documentar processo de desenvolvimento  

### ğŸŒ Sociais  
- Promover inclusÃ£o de pessoas com deficiÃªncia auditiva  
- Facilitar acesso a serviÃ§os bÃ¡sicos e educaÃ§Ã£o  
- Impactar inicialmente 20-30 usuÃ¡rios  

## ğŸš€ Tecnologias  

**NÃºcleo do Sistema**  
- Python
- Matplotlib
- Tensorflow
- MediaPipe
- Joblib

**Processamento de Imagem**  
- OpenCV
- Pillow
- Numpy

## âœ¨ Funcionalidades  

- âœ… **Reconhecimento de Libras:** Captura de gestos via cÃ¢mera e conversÃ£o em tempo real para texto em tempo real. 
- âœ… **ConversÃ£o Texto-Ãudio (TTS):** TransformaÃ§Ã£o do texto reconhecido em fala, permitindo a comunicaÃ§Ã£o auditiva.
- âœ… **Scripts de Coleta de Dados:** Ferramentas para a coleta e preparaÃ§Ã£o de dados, essenciais para o treinamento e aprimoramento dos modelos de IA.
- âœ… **Modelos de IA PrÃ©-treinados:** UtilizaÃ§Ã£o de dados estÃ¡ticos e dinÃ¢micos para garantir o funcionamento preciso da inteligÃªncia artificial.
- âœ… **Scripts de Treinamento de Modelo:** Ferramentas para a geraÃ§Ã£o e atualizaÃ§Ã£o dos modelos de IA (model.pkl, sequence_model.h5, label_map.npy).

## âš™ï¸ PrÃ©-requisitos  

Para executar o projeto localmente, vocÃª precisarÃ¡ de:

- Python: Uma versÃ£o compatÃ­vel (recomenda-se a versÃ£o 3.9.9 ou mais recente).
- CÃ¢mera: Uma cÃ¢mera funcional conectada ao seu computador para a captura de gestos.
- Bibliotecas Python: Todas as dependÃªncias listadas no requirements.txt.
- Uma IDE (Visual Studio Code, PyCharm, etc.) para desenvolvimento e execuÃ§Ã£o.
- Armazenamento livre mÃ­nimo: 4GB+ RAM e 2GB+ disco   

## ğŸ› ï¸ InstalaÃ§Ã£o  

1. Clone o repositÃ³rio:
```bash
git clone https://github.com/seu-usuario/LibraVoice.git
```

2. Navegue atÃ© o diretÃ³rio do projeto:
```bash
cd LibraVoice
```

3. (Opcional recomendÃ¡vel) Crie e ative um ambiente virtual:
> Ã‰ altamente recomendado usar um ambiente virtual para gerenciar as dependÃªncias.
```bash
# No Windows
python -m venv venv
.\venv\Scripts\activate
# ou # No macOS/Linux
source venv/bin/activate
```

4. Instale as dependÃªncias:
```bash
pip install -r requirements.txt
```

## â— Como Utilizar

1. Inicie o programa:
```bash
python app/main.py
```

2. Interaja com a cÃ¢mera:
Posicione-se em frente Ã  cÃ¢mera para que o sistema possa capturar seus gestos em Libras.

3. Observe a traduÃ§Ã£o:
O sistema exibirÃ¡ a traduÃ§Ã£o em texto e reproduzirÃ¡ a resposta em Ã¡udio, utilizando inteligÃªncia artificial.
> Ps: Apenas algumas Letras do alfabeto foram treinadas nesse modelo. (L,U,C,A,S,J,W)
### â–¶ï¸ DemonstraÃ§Ã£o

![Exemplo](https://raw.githubusercontent.com/gist/TheJLifeX/74958cc59db477a91837244ff598ef4a/raw/088f3995801c58f79f0a79086f1cd4cc176396d3/00-hand-gesture-recognition.gif)

*(GIF meramente ilustrativo)*  

## ğŸ“‚ Estrutura do Projeto  

```plaintext
LibraVoice/
â”œâ”€â”€ app/                    # ContÃ©m a lÃ³gica principal do software
â”‚   â”œâ”€â”€ data_collector...py # Scripts para coleta de dados de treinamento
â”‚   â”œâ”€â”€ tts.py              # Script para conversÃ£o de texto para Ã¡udio (Text-to-Speech)
â”‚   â””â”€â”€ main.py             # Script principal: captura imagem, converte para texto e gera Ã¡udio
â”œâ”€â”€ datasets/               # Armazena dados utilizados pelos modelos
â”‚   â”œâ”€â”€ data/               # Dados prÃ©-treinados estÃ¡ticos
â”‚   â””â”€â”€ data-seq/           # Dados prÃ©-treinados dinÃ¢micos
â”œâ”€â”€ models/                 # ContÃ©m os scripts e arquivos dos modelos de IA
â”‚   â”œâ”€â”€ model.py            # Script de treinamento do modelo principal
â”‚   â”œâ”€â”€ train_sequence_model.py # Script de treinamento do modelo de sequÃªncia
â”‚   â””â”€â”€ (arquivos de modelo gerados: model.pkl, sequence_model.h5, label_map.npy)
â”œâ”€â”€ .gitignore              # Arquivo de ignorar para controle de versÃ£o
â”œâ”€â”€ LICENSE                 # LicenÃ§a MIT
â”œâ”€â”€ README.md               # Este arquivo
â””â”€â”€ requirements.txt        # Lista de bibliotecas Python utilizadas
```

## ğŸ¤ ContribuiÃ§Ã£o
ContribuiÃ§Ãµes sÃ£o bem-vindas! Siga estas etapas:

1. Reporte bugs: Abra uma [issue](https://github.com/lucasgleria/LibraVoice/issues) no GitHub.
2. Sugira melhorias: Envie ideias ou pull requests com novas funcionalidades.
3. Desenvolva:
- FaÃ§a um fork do projeto.
- Crie uma branch (git checkout -b feature/nova-funcionalidade).
- Envie um Pull Request.

## ğŸ“œ LicenÃ§a  

DistribuÃ­do sob licenÃ§a MIT. Veja [LICENSE](LICENSE) para mais informaÃ§Ãµes. 

## ğŸ“ Contato
- **Autor**: [Lucas Leria](https://github.com/lucasgleria)
- **LinkedIn**: [lucasgleria](https://www.linkedin.com/in/lucasgleria/)

## ğŸ” Recursos Adicionais  

- [DocumentaÃ§Ã£o TensorFlow](https://www.tensorflow.org/)  
- [SoluÃ§Ãµes MediaPipe](https://ai.google.dev/mediapipe)  
- [OpenCV para Python](https://docs.opencv.org/)  
- [Artigo do Projeto](imagens/artigo/artigo.pdf)  

> Projeto acadÃªmico desenvolvido como trabalho de extensÃ£o da [EstÃ¡cio](https://estacio.br/)
